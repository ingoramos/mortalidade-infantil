---
title: "testes_modelos"
output: html_document
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
#Importação das bibliotescas
library(readr)
library(plyr)
library(chron)#transformar caracter em hora
library(tidyverse)
library(reshape)
library(forcats)#ordenar barras no ggplot
library(gridExtra)#arrumar multiplos gráficos em uma figura
library(knitr)
library(kableExtra)#Fazer tabela do summary
library(pander)#Fazer tabela do chi.test
library(caret)#K-fold cross validation
library(caTools)#Calcular AUC
library(ROSE) #dealing with imbalanced data
library(plotly) #gráficos interativos
library(doParallel) #Parallel Processing
library(mice) #Input de valores para substituir NA
library(tibble) #tabelas
library(fastAdaboost) #AdaBoost Classification Trees
library(gbm) #Stochastic Gradient Boosting
library(binda) #modelo Binary Discriminant Analysis
library(nnet) #Bayesian Regularized Neural Networks
library(xgboost) #eXtreme Gradient Boosting
library(deepnet) #Stacked AutoEncoder Deep Neural Network
library(MASS) #Generalized Linear Model with Stepwise Feature Selection
library(LiblineaR) #SVM
library(ggplot2) #plots
library(corrgram) #correlograma
library(data.table) #otimização do uso de dataframes
```


#Importando as bases completas
```{r}
sinasc <- read.csv(file = "sinasc_treino.csv")
sinasc <- sinasc[, -1]
mort_infantil_18 <- read.csv(file = "mort_infantil_18.csv")
mort_infantil_18 <- mort_infantil_18[, -1]


sinasc$GESTACAO_SINASC <- as.factor(sinasc$GESTACAO_SINASC)
sinasc$PARTO_SINASC <- as.factor(sinasc$PARTO_SINASC)
sinasc$APGAR1_SINASC <- as.factor(sinasc$APGAR1_SINASC)
sinasc$APGAR5_SINASC <- as.factor(sinasc$APGAR5_SINASC)
sinasc$IDANOMAL_SINASC <- as.factor(sinasc$IDANOMAL_SINASC)
sinasc$ESCMAE2010_SINASC <- as.factor(sinasc$ESCMAE2010_SINASC)
sinasc$GRAVIDEZ_SINASC <- as.factor(sinasc$GRAVIDEZ_SINASC)
sinasc$CONSULTAS_SINASC <- as.factor(sinasc$CONSULTAS_SINASC)


mort_infantil_18$GESTACAO_SINASC <- as.factor(mort_infantil_18$GESTACAO_SINASC)
mort_infantil_18$PARTO_SINASC <- as.factor(mort_infantil_18$PARTO_SINASC)
mort_infantil_18$APGAR1_SINASC <- as.factor(mort_infantil_18$APGAR1_SINASC)
mort_infantil_18$APGAR5_SINASC <- as.factor(mort_infantil_18$APGAR5_SINASC)
mort_infantil_18$IDANOMAL_SINASC <- as.factor(mort_infantil_18$IDANOMAL_SINASC)
mort_infantil_18$ESCMAE2010_SINASC <- as.factor(mort_infantil_18$ESCMAE2010_SINASC)
mort_infantil_18$GRAVIDEZ_SINASC <- as.factor(mort_infantil_18$GRAVIDEZ_SINASC)
mort_infantil_18$CONSULTAS_SINASC <- as.factor(mort_infantil_18$CONSULTAS_SINASC)
```


#Função
```{r}
pred_mort <- function(bancoTreino, bancoPred){
  
  set.seed(2)
  
  # dados para treino
  train_data <- bancoTreino
  
  # dados para controle do teste
  test_ctrl <- bancoPred
  
  # dados para o teste
  test <- test_ctrl[, -which(names(test_ctrl) %in% c("OBITO"))]

  #lista com os métodos de balanceamento
  sampling_methods <- c("down", "up", "smote")
  j <- 1
  sm_index <- 1
  
  for(j in length(sampling_methods)){
    
    sm_index <- sm_index + 1
    j <- j + 1
    
    #Create train/test index
    # Create trainControl object: myControl - Deve ser utilizado em todos os modelos para que sejam comparáveis
    myControl <- trainControl(
      method = "cv", #"repeatedcv" é o método para realizar as repetições
      number = 2, #number é o número de folds
      #repeats = 1, #repeats é o número de repetições para cada fold
      summaryFunction = twoClassSummary,
      classProbs = TRUE, # IMPORTANT!
      verboseIter = FALSE,
      savePredictions = TRUE,
      returnResamp = "all",
      sampling = sampling_methods[sm_index], #balanceamento dos dados
      allowParallel = TRUE
    )
    
      #lista de modelos que serão usados inicialmente 
      # "glm" = Generalized Linear Model, "ranger" = Random Forest, "knn" = k-Nearest Neighbors, 
      #"nnet" = Neural Network, "dnn" = Stacked AutoEncoder Deep Neural Network, 
      #"xgbTree" = eXtreme Gradient Boosting, "gbm" = Stochastic Gradient Boosting, "adaboost" = AdaBoost Classification Trees.
      
      # "glm", "ranger", "knn", "gbm", "nnet", "adaboost", "xgbTree", "dnn"
      modelos <- c("glm")
      
      i <- 1 #indice para atualizar o while
      index <- 1 #indice que retorna o modelo da lista
      maior_valor <- 0 #usado para verificar qual o modelo com maior valor preditivo negativo.
      #espec <- 0 #usado para verificar qual o modelo com maior especificidade.
      
      #lista com os métodos de balanceamento
      metrics <- c("ROC", "Sens")
      k <- 1
      m_index <- 1
      
      for(k in length(metrics)){
        
        m_index <- m_index + 1
        k <- k + 1
      
        #loop para selecionar o melhor algoritmo
        while(i <= length((modelos))) {
          
          # Fit model
          model <- train(
          OBITO ~ . , #variável preditiva
          data = train_data, #banco de treino
          preProcess = c("center", "scale"),
          metric = metrics[m_index], # métrica para comparação dos modelos
          method = modelos[index], #lista com indice (retorna uma string com o nome do método para cada modelo)
          trControl = myControl #aplica o controle
          
          )
          
          #fazendo a matriz de confusão para o banco de treino    
          banco_model <- model$trainingData
      
          banco_model$.outcome <- as.factor(banco_model$.outcome)
      
          cm_t <- confusionMatrix(banco_model$.outcome, sample(banco_model$.outcome))
          
      
          # Print model to console
          model
          
          # Print maximum ROC statistic
          max(model[["results"]][["ROC"]])
          
          #predição dos modelos no banco para matriz de confusão
          predictionsCM <- predict(model, test)
          
          #predição dos modelos no banco para probabilidade
          predictions <- predict(model, test, type = "prob")
          
          #o test_control é usado para comparação com os valores da predição, gerando a matriz de confusão.
          cm <- confusionMatrix(predictionsCM, test_ctrl$OBITO)
          
          #extraindo os resultados da matriz de confusão
          cm_results <- cm$byClass %>% as.list()
          
          #extraindo a sensibilidade
          sens <- cm_results[1] %>% as.data.frame()
          sens <- sens$Sensitivity
          
          
          #verificação do maior valor preditivo negativo, como inicialmente o maior valor está atribuído como 0, o primeiro modelo sempre terá o maior valor, ou seja, sempre que um modelo conseguir alcançar um valor preditivo negativo maior que o armazenado na memória, este passa a ser o instrumento de verificação.
          if(sens > maior_valor){
            maior_valor <- sens #valor preditivo positivo passa a ser o maior valor
            resultado <- paste("O melhor modelo foi: ", modelos[index], ", usando o método de balanceamento: ", sampling_methods[sm_index], "com a métrica: ", metrics[m_index], ", com sensibilidade de: ", sens) #mensagem para informar o modelo com melhor resultado
            cm_melhor <- cm #cm armazena os dados da matriz de confusão (teste) do melhor modelo
            cm_t_melhor <- cm_t #cm_t armazena os dados da matriz de confusão (treino) do melhor modelo
            melhor_modelo <- model
            
            #colando a coluna da predição para comparar com a real
            resultados <- cbind(test_ctrl, predictions)
            
            #cria uma coluna com a probabilidade em % de OBITO
            resultados["Prob"] <- resultados$sim * 100
            
            modelo <- modelos[index]
            samp <- sampling_methods[sm_index]
            metrica <- metrics[m_index]
            
          }
          else{
            maior_valor <- maior_valor #caso a verificação falhe, o maior_valor continua sendo ele mesmo ("atual")
          }
          
          #atualiza o indice para o i (while), e index (lista de modelos)
          i <- i + 1
          index <- index + 1
          
        }
      }
  }
    #desenha a matriz de confusão para o cm armazenado com o melhor modelo
   # cm_p <- draw_confusion_matrix(cm_melhor)  
  
  #retorno da função (matriz de confusão de treino (cm_t), mensagem de resultado (resultado), desenho da matriz de confusão de teste (cm_p))
  return(melhor_modelo)
  
}

```


```{r}
pred_mort(sinasc, mort_infantil_18)
```


